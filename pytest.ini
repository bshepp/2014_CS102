[tool:pytest]
# Pytest configuration for the N-Dimensional Geometry Engine

# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output options
addopts = 
    -v
    --strict-markers
    --tb=short
    --color=yes
    --durations=10
    --strict-config
    --doctest-modules
    --doctest-continue-on-failure

# Markers
markers =
    unit: Unit tests
    integration: Integration tests
    performance: Performance tests
    mathematical: Mathematical accuracy tests
    api: API endpoint tests
    tiling: Tiling functionality tests
    slow: Slow-running tests (> 1 second)
    requires_java: Tests requiring Java installation
    benchmark: Benchmark tests
    stress: Stress tests
    scalability: Scalability tests
    memory: Memory usage tests
    concurrency: Concurrency tests

# Test collection
minversion = 7.0
required_plugins = 
    pytest-cov
    pytest-benchmark
    pytest-mock
    pytest-asyncio
    pytest-html

# Coverage settings
addopts = --cov=geometry_engine --cov=web_api --cov-report=term-missing --cov-report=html --cov-report=xml
# --cov-fail-under=80  # Uncomment to require 80% coverage

# Performance settings
benchmark_only = false
benchmark_sort = mean
benchmark_group_by = name
benchmark_min_rounds = 5
benchmark_max_time = 60
benchmark_warmup = true
benchmark_disable_gc = false

# Timeout settings
timeout = 300
timeout_method = thread

# Asyncio settings
asyncio_mode = auto

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Warnings
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning:plotly.*
    ignore::DeprecationWarning:scipy.*
    ignore::PendingDeprecationWarning

# Test selection shortcuts
# Run with: pytest -m unit
# Run with: pytest -m "not slow"
# Run with: pytest -m "unit and not requires_java"
# Run with: pytest -m "performance and benchmark"

# Parallel execution (requires pytest-xdist)
# addopts = -n auto  # Uncomment to enable parallel test execution

# HTML report settings
# Generate with: pytest --html=report.html --self-contained-html